# compiler
An exploration of how to structure a compiler's dataflow.

## source overview
[src/main_jc2.cpp](src/main_jc2.cpp) -- All the code lives here.
There's some older code in src/c_* files, but none of those are used in this newer compiler.
I was experimenting with a single-sourcefile project here, so all the non-shared code is really dumped into src/main_jc2.cpp.
It wasn't that bad of an experience; the main thing I found lacking was support for multiple views of the same file in my editor.
It's ~8,500 LOC in the one sourcefile, which is really not that bad as a single file. Definitely workable, doesn't really affect much.

## background

This was a project solely for me to learn about how a compiler can work from first principles. It's not targeted at any specific pre-existing language; it's a mishmash of very simple language ideas that meets some minimum bar of complexity to make this a challenge.

## tokenization

Things start with tokenization, which generates a simple list of token_t objects. Each of these points back to the source text, so you can always get back to file/line info if you need to. This is primarily beneficial for error output, but also helps with debugging. Generating and storing the whole list is an explicitly simple strategy; I think most compilers do this as an on-demand thing, only reading ahead as little as possible. I'm not sure there's any benefit to that these days; if you can load the whole source text into memory, probably you can also load the whole token stream, since it's going to be some smaller proportion of the source text in size, generally. There's also a token post-processor, which runs after the whole token stream is generated, doing things like: removing comment spans, converting literals to explicit token types, etc.

## parsing

The simplest possible parsing solution I could think of is to just start walking the token stream in order, and start constructing meaningful elements of the language from that. So the primary functions here are to: reject incorrect syntax with meaningful error messages, and build a tree structure representing the language syntax from the tokens seen. Basically, it's one very complicated loop over the token stream that outputs a strongly-typed tree structure.

There's some interesting design questions here about using a fully generic tree structure vs. a strongly-typed one. The convenience of having a universal FORCHILDREN iterator might be nice, but that also confuses things when you've got more complex things that are more graph-like than strictly tree-like. The generic structure also doesn't really buy you extensibility, because the language syntax is so strictly defined, that you have to change every expansion point when you add/change/delete elements of the syntax. So I'm not convinced you get much in terms of extensibility that's useful.

This is effectively what's called "recursive descent parsing" by literature, and it seems pretty reasonable to me. The mountain of datastructures embedding the syntax is already enough complexity, I doubt it's worth throwing on additional complicated parsing algorithms. I could be wrong though, I haven't tried implementing things like the reverse or table based parsing algorithms.

The "left recursive grammar" problem is also pretty interesting; you have to structure this kind of sequential parsing to avoid infinite recursion, which is relatively easy to do with expressive mathematical syntax. The solution is basically to factor your parsing to exclude things that recurse and generate no token progress, and generate intermediate syntax objects instead. E.g. ParseExprExcludingBinop which can't recurse into more binops, and then look for a binop next. One neat thing is you can fix up these intermediate syntax objects later, to get rid of this artificial exclusion. I didn't actually solve this problem here in this codebase, but I did in the expression parser of the csv project. So that's probably a better reference.

Another interesting design question is whether to use a flat byte encoding of the tree, or something more structured. The optimal perf thing to do is probably a straight byte encoding, which would have more fixed-offset memory addressing rather than pointer/address offsetting. But for clarity / typesafety, I just opted for pointers / linked lists for now. That bypasses a lot of the order of evaluation problems, e.g. reserving space for something that we'll  compute later. But some things are trivial to embed, like syntax object type, name of identifier, etc. The allocations for syntax objects all go into a sequential stack-list allocator. Being a linked list of fixed-size stacks, it's trivial to organize things s.t. all syntax objects are packed together closely, up to the stack capacity, where we start a new stack. I haven't tested the perf compared to other allocation strategies, but it's simple enough that it's fast enough for this.

Binary operator precedence is another interesting problem exposed by this code. Getting the order of evaluation of math-like syntax is tricky if you haven't considered it before, and I hadn't really. My solution ( also not present here, but in the csv project's expression parser ) is to pass down the previous binary operator in the chain, as you're parsing. So for (a/b+c), when parsing the + binary operator, pass down the knowledge that the / operator was the previous in a chain. Then you can basically rotate the tree to pick the appropriate parent operator, according to the relative precedences. Depending on how strong/weak the unary operators are too, you may have to also track that. The most helpful thing here was to ignore this as a problem until I wrote enough test cases to verify precedence was working correctly. As said before, it's not working here :)

Error handling is relatively tricky here in parsing. How do you continue parsing if you find unexpected tokens that don't match the grammar? For simplicity I've just taken the easy way out, exiting early if any are found. This amounts to some generous but specific uses of IER macros, meaning "if error return". Software exceptions are also a reasonable solution here, I just wasn't sure if I had to rely on error cases firing commonly, and didn't want to rely on exceptions unless they rarely fire. This was somewhat proven true with statement parsing, in which you can have an almost-ambiguous situation when a statement starts with an identifier, in our syntax. Since things were ambiguous, the not-so-great solution was to try multiple possible options, and see which one stuck. Since we're expecting parsing failures here, catching exceptions on purpose feels a little strange, just as a style concern. Getting into the habit of catching exceptions seems like a bad idea in general, although it probably could simplify some things here if used correctly. But I haven't tried to implement parse failure recovery yet, so maybe I'd find something concerning there.

## type checking

After parsing, the input is verified to be fully adherent to the language grammar, or if not, then we've printed errors and exited. Type checking is the data pass that decides whether the given syntax tree follows the type rules. E.g. assigning a string to an integer variable doesn't really make sense, even if it's allowed in the syntax. This was structured as a recursive tree visitor essentially, with roughly one function per syntax object, which type checks it's children, and then itself as a combination of its children. That's the big picture view.

I originally had this as the perhaps more traditional method, where you encode type information into the syntax objects, and use those as the source of truth. I found this unsatisfying, because you still had to do basically all the work to keep track of stack variables in scopes, and look up names as appropriate while typechecking things. And building a list of typed stack variables is a whole complicated data structure on it's own, let alone plugging that stuff into the already crazy syntax tree. So I switched to a fully generating method, where type checking constructs it's own tree structure of typed things. In some cases these are roughly equivalent to the syntax objects, but in other cases not. E.g. functions/procedures have to track all stack variables they own, and some syntax objects represent underlying operations we can easily unpack during typing, where we have all information available. Trying to do some of the unpacking later on is harder; you basically need to duplicate all of the syntax tree iteration and control flow if you don't do it here. So even though it makes type checking code relatively complicated, the benefit is not having two copies of slightly less complicated code to maintain and keep in sync.

This leads to interesting code-generation-like things we'll do during type checking, just because it's the easiest and best place to do it. So as we type check a function, we'll keep track of which function we're in, and allocate stack variables as necessary. And since we're already generating stack variables so we can lookup types, it's really the best time to emit pseudo-instructions that operate on the level of typed stack variables. So when we're type checking "a = b + c", since we're explicitly determining the types of everything and which stack variables are involved, we emit an instruction to do the addition and store the result in "a". This introduces some sequencing requirements on the type checking code, in order to generate code that's in order and sensible. But it's not too difficult in most cases.

Another example of code-generation kinds of things happening during type checking is: converting control flow syntax into labels and jumps. We already have to type check if/while-conditions and their scope children, so we may as well just emit the pseudo-instructions in a simpler format, to avoid having to deal with complicated control flow in the later machine code generators. "break"/"continue" in loops are another example of complicated control flow that we can handle during type checking, even though it might seem unrelated on its face. Centralizing all this logic into type checking means we'll never have to go back to consult the syntax objects after this phase, which is hugely helpful in separating the concerns of the fancy language syntax from the instruction format, even if it's our temporary one not shared by other languages.

One really interesting thing to implement was automatic casting. In the vein of "int8_t a;  int16_t b = a;", generate an appropriate upcast operation to do this automatically. The basic strategy I used was to generate a list of all potential types a given type could automatically cast to, alongside the fundamental type itself. Then when using that typed expression, generate an "automatic cast" operation at the point of use, if it's allowed according to the context and given list of potential types. If not, print an error saying we can't automatically cast to the desired type. This game of keeping track of potential types we can cast to was definitely trickier than I thought it would be. It took a couple of iterations to get to a simple system of generating and reducing potential types.

On the other hand, I thought type inference was going to be super hard, in the vein of "auto x = Foo();". It turns out to be incredibly trivial; just use the given return type of the function Foo(). With an appropriately powerful automatic casting system, that's really all you want. Anything more powerful, e.g. allowing "auto x" to have an undetermined fundamental type until it gets used later, is probably not what any programmer wants. But it does seem like an interesting point of research, can you do more generic type programming like this, instead of the fundamental-type based approach like C++ templates where you really only care about instantiations? Hopefully you'd close the door at compile-time in all cases, or else you're giving up the benefits of a statically typed language, and allowing runtime type errors in. I can see a way in which you can probably simplify language syntax by using the same "auto" keyword or whatever in the places template types are usually specified, which might actually be great.

One surprising thing was how complicated it was to implement the combination of array-dereference and struct-dereference, e.g. "foo.bar\[10\].car". For whatever reason I wanted to try unwinding the recursion and use looping instead, which made things harder to understand, but allowed easy access to previous things. I doubt this was worth it. But the main point of complexity was, what happens when this kind of expression is on the left vs. right side of an assignment? If it's on the left, we want to treat it as a pointer to assign into. But if it's on the right, we want to treat it as a value we're reading. This difference in context means you have to very carefully track what happens at every level of the array-dereferences and struct-dereferences. Basically for everything in the dot/bracket chain, we emit some combination of operations like: (p)element_from_(p)array and (p)field_from_(p)struct, for every combination of (p) being present or not. Essentially there's cases like assignment where we want to generate a stack variable containing either the value, or a pointer to the value. And you need different type checking logic for those cases. See TypeExprAssignable for the craziness. One simplification
might be to just always generate the pointer instructions, and conditionally add a final dereference if we want the value itself. I'd have to dig into the details again to decide if that's worth doing; it might be.

## "machine" code generation and execution

As a way to understand the space better, since I knew so little about it, I wrote a small stack-based virtual machine to execute a bytecode instruction set. Look for bc_t and bc_type_t to see the bytecode instructions themselves. Each function knows how much stack space it requires and where it's stack variables are positioned in that space, so the bytecode instructions are essentially all operations between stack variables, with the RISC idea of just having load/store as the exceptions. The primary complexity is around function calls, which have to push/pop space on the stack, store the return address, and then jump back to that location when executing a "ret" instruction.

One interesting thing was the space of possibilities for defining calling conventions even on a non-register, stack-variable virtual machine. For example, should you pass stack-frame-relative offsets to stack variables? I guess this is specific to the virtual machine aspect of this; if you're in actual machine code, you just generate absolute addresses. But in the software VM, you're always doing the addition from the base of the stack frame anyways, so it's an interesting question when to do the adds. Absolute addressing is probably simplest, so maybe I should just do that. But I hadn't considered passing in a negative offset to the stack-frame pointer before, which seems like a neat idea. E.g. store results at (rsp - offset), where offset is a function parameter. Presumably ABIs don't do this because they don't specify exactly how much extra stuff gets shoved into stack frames, or it might be variable, I'm not sure.

